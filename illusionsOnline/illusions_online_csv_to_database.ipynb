{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91fb3e75-df68-4e27-a9fd-e634baec9885",
   "metadata": {},
   "source": [
    "## For illusoins online hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05079bf3-bb73-488a-b87e-ee7c8c121e1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hotelCode;hotelName;country;latitude;longitude;address;categoryCode;giataCode']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file = \"D:/Rokon/hotels_content_to_create_json_file/IllusionsOnline/illusions-online-aWxzLTMwMzM1.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb938467-0a4a-40d6-8ca6-ce21692023a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hotelCode;hotelName;country;latitude;longitude;address;categoryCode;giataCode']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file, nrows = 1)\n",
    "headers = df.columns.tolist()\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea229e4-1409-4eab-9143-775b2eaef4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2e45828-38b8-4dc9-8f14-ab34940a0145",
   "metadata": {},
   "source": [
    "### Add Column anly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce7ec61-133c-425b-8c2b-5cb0b2773b23",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added column: hotelCode (VARCHAR(255))\n",
      "Added column: hotelName (VARCHAR(255))\n",
      "Added column: country (VARCHAR(255))\n",
      "Added column: latitude (FLOAT)\n",
      "Added column: longitude (FLOAT)\n",
      "Added column: address (VARCHAR(255))\n",
      "Added column: categoryCode (FLOAT)\n",
      "Added column: giataCode (FLOAT)\n",
      "Columns update completed.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, MetaData, inspect\n",
    "from sqlalchemy.sql import text\n",
    "import pandas as pd\n",
    "\n",
    "# File and database setup\n",
    "file = \"D:/Rokon/hotels_content_to_create_json_file/IllusionsOnline/illusions-online-aWxzLTMwMzM1.csv\"\n",
    "df = pd.read_csv(file, delimiter=';', nrows=1) \n",
    "headers = df.columns.tolist()\n",
    "\n",
    "# Split and sanitize headers if they appear as a single string\n",
    "if len(headers) == 1 and ';' in headers[0]:\n",
    "    headers = headers[0].split(';')  # Split single string into list\n",
    "headers = [col.strip().replace(\" \", \"_\").replace(\"-\", \"_\") for col in headers]  \n",
    "\n",
    "DATABASE_URL = \"mysql+pymysql://root:@localhost/csvdata01_02102024\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "\n",
    "# Inspect existing table\n",
    "table_name = \"illusions_online\"\n",
    "inspector = inspect(engine)\n",
    "if table_name in inspector.get_table_names():\n",
    "    existing_columns = [col[\"name\"] for col in inspector.get_columns(table_name)]\n",
    "\n",
    "    # Dynamically add missing columns\n",
    "    with engine.connect() as conn:\n",
    "        for column_name in headers:\n",
    "            if column_name not in existing_columns:\n",
    "                column_type = \"FLOAT\" if column_name in ['latitude', 'longitude', 'categoryCode', 'giataCode'] else \"VARCHAR(255)\"\n",
    "                try:\n",
    "                    # Prepare and execute ALTER TABLE statement\n",
    "                    alter_statement = text(f\"ALTER TABLE `{table_name}` ADD COLUMN `{column_name}` {column_type}\")\n",
    "                    conn.execute(alter_statement)\n",
    "                    print(f\"Added column: {column_name} ({column_type})\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to add column {column_name}: {e}\")\n",
    "else:\n",
    "    print(f\"Table '{table_name}' does not exist.\")\n",
    "\n",
    "print(\"Columns update completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e473699-23e5-4cf4-b4fb-33b98cfc956b",
   "metadata": {},
   "source": [
    "### Upload CSV file to database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7858cf91-e6ec-41a2-bd44-7ee640080fb2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 1000 rows into the 'illutions_online' table.\n",
      "Columns in the CSV: Index(['hotelCode', 'hotelName', 'country', 'latitude', 'longitude', 'address',\n",
      "       'categoryCode', 'giataCode'],\n",
      "      dtype='object')\n",
      "Inserted a chunk of 535 rows into the 'illutions_online' table.\n",
      "Data insertion complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "import numpy as np\n",
    "\n",
    "DATABASE_URL = \"mysql+pymysql://root:@localhost/csvdata01_02102024\"\n",
    "engine = create_engine(DATABASE_URL, pool_size=10, max_overflow=20)  # Connection pool configuration\n",
    "\n",
    "chunk_size = 1000\n",
    "file = \"D:/Rokon/hotels_content_to_create_json_file/IllusionsOnline/illusions-online-aWxzLTMwMzM1.csv\"\n",
    "\n",
    "# Load the table metadata\n",
    "metadata = MetaData()\n",
    "\n",
    "# Reflect the table (without bind)\n",
    "illutions_online = Table('illusions_online', metadata, autoload_with=engine)\n",
    "\n",
    "# Read CSV in chunks, skipping bad lines\n",
    "for chunk in pd.read_csv(file, chunksize=chunk_size, on_bad_lines='skip', delimiter=';'):\n",
    "    # Handle missing values or data type conversions using `map` instead of `applymap`\n",
    "    chunk = chunk.apply(lambda x: None if isinstance(x, float) and np.isnan(x) else x)\n",
    "    \n",
    "    # Check the column names in the chunk for debugging\n",
    "    print(\"Columns in the CSV:\", chunk.columns)\n",
    "\n",
    "    # Insert the chunk into the table\n",
    "    try:\n",
    "        chunk.to_sql('illusions_online', con=engine, if_exists='append', index=False)\n",
    "        print(f\"Inserted a chunk of {len(chunk)} rows into the 'illutions_online' table.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data: {e}\")\n",
    "\n",
    "print(\"Data insertion complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb07f03-b7cf-473f-8403-a61220b38961",
   "metadata": {},
   "source": [
    "### Illusions hotel table to local iit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36f6477-c9c4-4952-b3b0-8d00860ddb70",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 of 24 completed\n",
      "Batch 2 of 24 completed\n",
      "Batch 3 of 24 completed\n",
      "Batch 4 of 24 completed\n",
      "Batch 5 of 24 completed\n",
      "Batch 6 of 24 completed\n",
      "Batch 7 of 24 completed\n",
      "Batch 8 of 24 completed\n",
      "Batch 9 of 24 completed\n",
      "Batch 10 of 24 completed\n",
      "Batch 11 of 24 completed\n",
      "Batch 12 of 24 completed\n",
      "Batch 13 of 24 completed\n",
      "Batch 14 of 24 completed\n",
      "Batch 15 of 24 completed\n",
      "Batch 16 of 24 completed\n",
      "Batch 17 of 24 completed\n",
      "Batch 18 of 24 completed\n",
      "Batch 19 of 24 completed\n",
      "Batch 20 of 24 completed\n",
      "Batch 21 of 24 completed\n",
      "Batch 22 of 24 completed\n",
      "Batch 23 of 24 completed\n",
      "Batch 24 of 24 completed\n",
      "Data transfer completed\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, Table, MetaData, insert\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import pandas as pd\n",
    "\n",
    "DATABASE_URL = \"mysql+pymysql://root:@localhost/csvdata01_02102024\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "metadata = MetaData()\n",
    "\n",
    "metadata.reflect(engine)\n",
    "\n",
    "illusionsHotel = Table('illusions_online', metadata, autoload=True, autoload_with=engine)\n",
    "innovativeHotel = Table('innova_hotels_main', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "def transfer_all_data():\n",
    "    try:\n",
    "        # Get total rows using raw SQL query\n",
    "        total_rows = session.execute(illusionsHotel.select()).rowcount\n",
    "        batch_size = 1000\n",
    "        total_batches = (total_rows // batch_size) + (1 if total_rows % batch_size > 0 else 0)\n",
    "        \n",
    "        for batch in range(total_batches):\n",
    "            offset = batch * batch_size\n",
    "            # Use SQLAlchemy Core to construct the query\n",
    "            query = illusionsHotel.select().limit(batch_size).offset(offset)\n",
    "            df = pd.read_sql(query, con=engine)\n",
    "            rows = df.astype(str).to_dict(orient='records')\n",
    "\n",
    "            # Process rows without nested transactions\n",
    "            for row in rows:\n",
    "                keys_to_extract = ['Id', 'hotelCode', 'supplierCode', 'hotelName', 'country', 'latitude', 'longitude', 'address', 'categoryCode', 'giataCode']\n",
    "                filtered_row_dict = {key: row.get(key, None) for key in keys_to_extract}\n",
    "\n",
    "                data = {\n",
    "                    'HotelId': filtered_row_dict.get(\"hotelCode\", None),\n",
    "                    'GiataCode': filtered_row_dict.get(\"giataCode\", None),\n",
    "                    'CountryCode': filtered_row_dict.get(\"country\", None),\n",
    "                    'HotelName': filtered_row_dict.get(\"hotelName\", None),\n",
    "                    'Latitude': filtered_row_dict.get(\"latitude\", None),\n",
    "                    'Longitude': filtered_row_dict.get(\"longitude\", None),\n",
    "                    'AddressLine1': filtered_row_dict.get(\"address\", None),\n",
    "                    'SupplierCode': filtered_row_dict.get(\"supplierCode\", None)\n",
    "                }\n",
    "\n",
    "                stmt = insert(innovativeHotel).values(data)\n",
    "                session.execute(stmt)\n",
    "            session.commit()  # Commit after processing the batch\n",
    "            print(f\"Batch {batch + 1} of {total_batches} completed\")\n",
    "        \n",
    "        print(\"Data transfer completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        session.rollback()\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "transfer_all_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3eac04-8103-45bb-a854-0eeb0bb26bc3",
   "metadata": {},
   "source": [
    "## Server IIT table to Vervotech mapping Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96ac708e-a111-439a-8b68-182cc2006774",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data insertion process...\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 1 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 2 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 3 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 4 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 5 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 6 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 7 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 8 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 9 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 10 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 11 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 12 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 13 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 14 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 15 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 16 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 17 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 18 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 19 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 20 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 21 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 22 inserted successfully.\n",
      "Fetched 1000 records from the database.\n",
      "Chunk 23 inserted successfully.\n",
      "Fetched 535 records from the database.\n",
      "Chunk 24 inserted successfully.\n",
      "No more records to transfer.\n",
      "Data insertion completed.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Database credentials from .env\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_pass = os.getenv('DB_PASSWORD')\n",
    "db_name = os.getenv('DB_NAME')\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "SERVER_DATABASE_URL = f\"mysql+pymysql://{db_user}:{db_pass}@{db_host}/{db_name}\"\n",
    "server_engine = create_engine(SERVER_DATABASE_URL)\n",
    "\n",
    "def insert_data_in_chunks(engine, chunk_size, page_size):\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"Starting data insertion process...\")\n",
    "\n",
    "    select_query = text(\"\"\"\n",
    "        SELECT * FROM innova_hotels_main\n",
    "        WHERE SupplierCode =  'illusionshotel'\n",
    "        LIMIT :limit OFFSET :offset\n",
    "    \"\"\")\n",
    "\n",
    "    insert_query = text(\"\"\"\n",
    "        INSERT INTO vervotech_mapping (\n",
    "            last_update, VervotechId, GiataCode, ProviderHotelId, ProviderFamily, status,\n",
    "            ModifiedOn, hotel_city, hotel_name, hotel_country, hotel_longitude,\n",
    "            hotel_latitude, country_code, content_update_status, created_at\n",
    "        )\n",
    "        VALUES (:last_update, :VervotechId, :GiataCode, :ProviderHotelId, :ProviderFamily, :status,\n",
    "                :ModifiedOn, :hotel_city, :hotel_name, :hotel_country, :hotel_longitude,\n",
    "                :hotel_latitude, :country_code, :content_update_status, :created_at)\n",
    "    \"\"\")\n",
    "\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            offset = 0\n",
    "            chunk_count = 1\n",
    "\n",
    "            while True:\n",
    "                # Fetch a small batch of data at a time\n",
    "                result = connection.execute(select_query, {'limit': page_size, 'offset': offset}).fetchall()\n",
    "\n",
    "                if not result:\n",
    "                    print(\"No more records to transfer.\")\n",
    "                    break\n",
    "\n",
    "                print(f\"Fetched {len(result)} records from the database.\")\n",
    "                offset += page_size\n",
    "\n",
    "                data_to_insert = []\n",
    "                for row in result:\n",
    "                    data_to_insert.append({\n",
    "                        'last_update': current_time,\n",
    "                        'VervotechId': None,\n",
    "                        'GiataCode': row[3],\n",
    "                        'ProviderHotelId': row[5], \n",
    "                        'ProviderFamily': row[4], \n",
    "                        'status': \"Update\",\n",
    "                        'ModifiedOn': current_time,\n",
    "                        'hotel_city': row[7],  \n",
    "                        'hotel_name': row[15],\n",
    "                        'hotel_country': row[12],  \n",
    "                        'hotel_longitude': row[17],\n",
    "                        'hotel_latitude': row[16], \n",
    "                        'country_code': row[13], \n",
    "                        'content_update_status': \"Done\",\n",
    "                        'created_at': current_time  \n",
    "                    })\n",
    "\n",
    "                if data_to_insert:\n",
    "                    try:\n",
    "                        # Execute the bulk insert\n",
    "                        connection.execute(insert_query, data_to_insert)\n",
    "                        print(f\"Chunk {chunk_count} inserted successfully.\")\n",
    "                        data_to_insert.clear()\n",
    "                        chunk_count += 1\n",
    "                        # Commit the transaction after each chunk\n",
    "                        connection.commit()\n",
    "                    except SQLAlchemyError as e:\n",
    "                        print(f\"Error during insert operation for chunk {chunk_count}: {e}\")\n",
    "                        connection.rollback()\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Error during database operation: {e}\")\n",
    "\n",
    "    print(\"Data insertion completed.\")\n",
    "\n",
    "# Call the function to process data in chunks\n",
    "insert_data_in_chunks(server_engine, chunk_size=1000, page_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45a3da8-8000-463e-87b0-660833e9fd91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
